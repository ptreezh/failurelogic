"""
è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œå™¨

è¯¥æ‰§è¡Œå™¨è´Ÿè´£åè°ƒå’Œè¿è¡Œæ‰€æœ‰åœºæ™¯çš„éªŒè¯æµ‹è¯•
æä¾›ç»Ÿä¸€çš„æ¥å£æ¥æ‰§è¡Œæ‰¹é‡æµ‹è¯•å’Œç®¡ç†æµ‹è¯•æµç¨‹
"""

import asyncio
import json
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import logging
import signal
import sys
from concurrent.futures import ThreadPoolExecutor
import threading

from universal_scenario_validator import ScenarioTestFramework
from specific_scenario_validations import ComprehensiveScenarioValidator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test_executor.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class TestExecutionManager:
    """æµ‹è¯•æ‰§è¡Œç®¡ç†å™¨ - ç®¡ç†æ•´ä¸ªæµ‹è¯•æ‰§è¡Œæµç¨‹"""
    
    def __init__(self, base_url: str = "http://localhost:8000", max_concurrent: int = 1):
        self.base_url = base_url
        self.max_concurrent = max_concurrent  # ç”±äºæµè§ˆå™¨èµ„æºé™åˆ¶ï¼Œé€šå¸¸ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªæµ‹è¯•
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
        self.results = []
        self.lock = threading.Lock()
        self.interrupted = False
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨ä»¥ä¼˜é›…åœ°å¤„ç†ä¸­æ–­
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ - ç”¨äºä¼˜é›…åœ°åœæ­¢æµ‹è¯•"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…åœ°åœæ­¢æµ‹è¯•...")
        self.interrupted = True
    
    async def load_all_scenarios(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰åœºæ™¯å®šä¹‰"""
        logger.info("å¼€å§‹åŠ è½½æ‰€æœ‰åœºæ™¯å®šä¹‰...")
        
        framework = ScenarioTestFramework(base_url=self.base_url)
        framework.load_scenarios()
        
        logger.info(f"æˆåŠŸåŠ è½½ {len(framework.all_scenarios)} ä¸ªåœºæ™¯")
        return framework.all_scenarios
    
    async def run_single_scenario_validation(self, scenario: Dict) -> Dict:
        """è¿è¡Œå•ä¸ªåœºæ™¯çš„éªŒè¯"""
        if self.interrupted:
            logger.info(f"æµ‹è¯•å·²è¢«ä¸­æ–­ï¼Œè·³è¿‡åœºæ™¯: {scenario['name']}")
            return {
                'scenario_id': scenario['id'],
                'scenario_name': scenario['name'],
                'status': 'interrupted',
                'timestamp': datetime.now().isoformat()
            }
        
        logger.info(f"å¼€å§‹éªŒè¯åœºæ™¯: {scenario['name']}")
        
        try:
            validator = ComprehensiveScenarioValidator(base_url=self.base_url)
            result = await validator.validate_scenario_comprehensively(scenario)
            
            # æ·»åŠ æ‰§è¡Œæ—¶é—´æˆ³
            result['execution_timestamp'] = datetime.now().isoformat()
            
            logger.info(f"åœºæ™¯éªŒè¯å®Œæˆ: {scenario['name']}, æˆåŠŸ: {result['overall_success']}")
            return result
            
        except Exception as e:
            logger.error(f"éªŒè¯åœºæ™¯å¤±è´¥: {scenario['name']}, é”™è¯¯: {str(e)}")
            return {
                'scenario_id': scenario['id'],
                'scenario_name': scenario['name'],
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def run_batch_validation(self, scenarios: List[Dict], max_concurrent: int = 1) -> List[Dict]:
        """è¿è¡Œæ‰¹é‡éªŒè¯"""
        logger.info(f"å¼€å§‹æ‰¹é‡éªŒè¯ {len(scenarios)} ä¸ªåœºæ™¯")
        
        results = []
        
        # ç”±äºæµè§ˆå™¨èµ„æºé™åˆ¶ï¼Œæˆ‘ä»¬ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªæµ‹è¯•
        for i, scenario in enumerate(scenarios):
            if self.interrupted:
                logger.info("æµ‹è¯•æ‰§è¡Œè¢«ä¸­æ–­")
                break
                
            logger.info(f"è¿›åº¦: {i+1}/{len(scenarios)} - {scenario['name']}")
            
            # è¿è¡Œå•ä¸ªåœºæ™¯éªŒè¯
            result = await self.run_single_scenario_validation(scenario)
            results.append(result)
            
            # æ·»åŠ é—´éš”ä»¥é¿å…èµ„æºå†²çª
            if i < len(scenarios) - 1:  # ä¸åœ¨æœ€åä¸€ä¸ªåœºæ™¯åç­‰å¾…
                await asyncio.sleep(2)
        
        logger.info(f"æ‰¹é‡éªŒè¯å®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in results if r.get('overall_success', False))}/{len(results)}")
        return results
    
    async def run_comprehensive_test_suite(self) -> Dict:
        """è¿è¡Œå…¨é¢çš„æµ‹è¯•å¥—ä»¶"""
        start_time = datetime.now()
        logger.info(f"å¼€å§‹è¿è¡Œå…¨é¢æµ‹è¯•å¥—ä»¶ - æ—¶é—´: {start_time}")
        
        try:
            # 1. åŠ è½½æ‰€æœ‰åœºæ™¯
            all_scenarios = await self.load_all_scenarios()
            
            if not all_scenarios:
                logger.error("æœªæ‰¾åˆ°ä»»ä½•åœºæ™¯å®šä¹‰")
                return {
                    'status': 'error',
                    'error': 'No scenarios found',
                    'start_time': start_time.isoformat(),
                    'end_time': datetime.now().isoformat()
                }
            
            # 2. è¿è¡Œæ‰¹é‡éªŒè¯
            validation_results = await self.run_batch_validation(all_scenarios)
            
            # 3. ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
            total_scenarios = len(validation_results)
            successful_scenarios = sum(1 for r in validation_results if r.get('overall_success', False))
            failed_scenarios = total_scenarios - successful_scenarios
            error_scenarios = sum(1 for r in validation_results if r.get('status') == 'error')
            
            # 4. æ”¶é›†æ‰€æœ‰æ§åˆ¶å°é”™è¯¯
            all_console_errors = []
            for result in validation_results:
                if 'console_errors' in result:
                    all_console_errors.extend(result['console_errors'])
            
            end_time = datetime.now()
            
            comprehensive_result = {
                'status': 'completed',
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'duration_seconds': (end_time - start_time).total_seconds(),
                'total_scenarios': total_scenarios,
                'successful_scenarios': successful_scenarios,
                'failed_scenarios': failed_scenarios,
                'error_scenarios': error_scenarios,
                'success_rate': successful_scenarios / total_scenarios if total_scenarios > 0 else 0,
                'validation_results': validation_results,
                'total_console_errors': len(all_console_errors),
                'console_errors': all_console_errors,
                'interrupted': self.interrupted
            }
            
            logger.info(f"æµ‹è¯•å¥—ä»¶å®Œæˆ - æˆåŠŸç‡: {comprehensive_result['success_rate']*100:.1f}%")
            return comprehensive_result
            
        except Exception as e:
            logger.error(f"æµ‹è¯•å¥—ä»¶æ‰§è¡Œå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            return {
                'status': 'error',
                'error': str(e),
                'traceback': traceback.format_exc(),
                'start_time': start_time.isoformat(),
                'end_time': datetime.now().isoformat()
            }
    
    def save_execution_results(self, results: Dict, filename: str = None):
        """ä¿å­˜æ‰§è¡Œç»“æœåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"test_execution_results_{timestamp}.json"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = Path("test_results")
        output_dir.mkdir(exist_ok=True)
        
        filepath = output_dir / filename
        
        # ä¸ºäº†é¿å…JSONåºåˆ—åŒ–é—®é¢˜ï¼Œç§»é™¤å¯èƒ½æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡
        serializable_results = self._make_serializable(results)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ‰§è¡Œç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        return str(filepath)
    
    def _make_serializable(self, obj):
        """ä½¿å¯¹è±¡å¯åºåˆ—åŒ–"""
        if isinstance(obj, dict):
            return {key: self._make_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            return self._make_serializable(obj.__dict__)
        else:
            # å¯¹äºæ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                json.dumps(obj)
                return obj
            except TypeError:
                return str(obj)


class ParallelTestExecutor:
    """å¹¶è¡Œæµ‹è¯•æ‰§è¡Œå™¨ - å¦‚æœéœ€è¦æ›´é«˜æ€§èƒ½çš„æ‰§è¡Œ"""
    
    def __init__(self, base_url: str = "http://localhost:8000", max_parallel: int = 1):
        self.base_url = base_url
        self.max_parallel = max_parallel  # é™åˆ¶å¹¶è¡Œåº¦ä»¥é¿å…èµ„æºå†²çª
    
    async def run_with_semaphore(self, semaphore, scenario):
        """ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘"""
        async with semaphore:
            executor = TestExecutionManager(base_url=self.base_url, max_concurrent=1)
            return await executor.run_single_scenario_validation(scenario)
    
    async def run_parallel_validation(self, scenarios: List[Dict]) -> List[Dict]:
        """è¿è¡Œå¹¶è¡ŒéªŒè¯ï¼ˆå—é™å¹¶è¡Œä»¥é¿å…èµ„æºå†²çªï¼‰"""
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æµè§ˆå™¨å®ä¾‹æ•°é‡
        semaphore = asyncio.Semaphore(min(self.max_parallel, 3))  # æœ€å¤š3ä¸ªå¹¶è¡Œå®ä¾‹
        
        tasks = [
            self.run_with_semaphore(semaphore, scenario)
            for scenario in scenarios
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    'scenario_id': scenarios[i]['id'],
                    'scenario_name': scenarios[i]['name'],
                    'status': 'error',
                    'error': str(result),
                    'timestamp': datetime.now().isoformat()
                })
            else:
                processed_results.append(result)
        
        return processed_results


async def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œå®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•"""
    print("ğŸš€ å¯åŠ¨è®¤çŸ¥é™·é˜±åœºæ™¯è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œå™¨")
    print("="*70)
    print(f"ğŸ“‹ æµ‹è¯•ç›®æ ‡: éªŒè¯æ‰€æœ‰è®¤çŸ¥é™·é˜±åœºæ™¯çš„å®Œæ•´äº¤äº’åŠŸèƒ½")
    print(f"ğŸŒ æµ‹è¯•åœ°å€: http://localhost:8000")
    print(f"ğŸ¯ é¢„æœŸ: æ‰€æœ‰åœºæ™¯å‡èƒ½åœ¨Edgeæµè§ˆå™¨éheadlessæ¨¡å¼ä¸‹æ­£å¸¸å·¥ä½œ")
    print("="*70)
    
    # è¯¢é—®ç”¨æˆ·è¦æµ‹è¯•çš„URL
    import os
    test_url = os.getenv('TEST_URL', 'http://localhost:8000')  # é»˜è®¤æœ¬åœ°ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šè¿œç¨‹
    print(f"ğŸŒ å®é™…æµ‹è¯•URL: {test_url}")
    
    # åˆ›å»ºæ‰§è¡Œç®¡ç†å™¨
    executor = TestExecutionManager(base_url=test_url)
    
    try:
        # è¿è¡Œå…¨é¢æµ‹è¯•å¥—ä»¶
        print("\nğŸ” å¼€å§‹æ‰§è¡Œå…¨é¢æµ‹è¯•å¥—ä»¶...")
        results = await executor.run_comprehensive_test_suite()
        
        # ä¿å­˜ç»“æœ
        print("\nğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
        result_file = executor.save_execution_results(results)
        
        # è¾“å‡ºæ‘˜è¦
        print("\n" + "="*70)
        print("ğŸ“Š æµ‹è¯•æ‰§è¡Œæ‘˜è¦")
        print("="*70)
        
        if results['status'] == 'completed':
            print(f"æ€»åœºæ™¯æ•°: {results['total_scenarios']}")
            print(f"éªŒè¯æˆåŠŸ: {results['successful_scenarios']}")
            print(f"éªŒè¯å¤±è´¥: {results['failed_scenarios']}")
            print(f"æ‰§è¡Œé”™è¯¯: {results['error_scenarios']}")
            print(f"æˆåŠŸç‡: {results['success_rate']*100:.1f}%")
            print(f"æ€»è€—æ—¶: {results['duration_seconds']:.1f} ç§’")
            print(f"æ§åˆ¶å°é”™è¯¯æ•°: {results['total_console_errors']}")
            print(f"ç»“æœæ–‡ä»¶: {result_file}")
            
            if results['interrupted']:
                print("âš ï¸  æµ‹è¯•åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­è¢«ä¸­æ–­")
            
            print("\nâœ… è‡ªåŠ¨åŒ–æµ‹è¯•æ‰§è¡Œå™¨è¿è¡Œå®Œæˆ!")
            
            # æ ¹æ®æˆåŠŸç‡å†³å®šé€€å‡ºç 
            if results['success_rate'] >= 0.8:  # 80%ä»¥ä¸ŠæˆåŠŸç‡è®¤ä¸ºæˆåŠŸ
                print("ğŸ‰ æµ‹è¯•æˆåŠŸç‡è¾¾æ ‡!")
                return True
            else:
                print("âš ï¸ æµ‹è¯•æˆåŠŸç‡æœªè¾¾æ ‡ï¼Œéœ€è¦æ£€æŸ¥å¤±è´¥çš„åœºæ™¯")
                return False
        else:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {results.get('error', 'Unknown error')}")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return False
    except Exception as e:
        logger.error(f"æ‰§è¡Œå™¨è¿è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)